\babel@toc {english}{}
\contentsline {section}{\numberline {0.1}Key Papers}{3}{section.0.1}
\contentsline {chapter}{\numberline {1}Speech Recognition in a Medical Environment}{5}{chapter.1}
\contentsline {section}{\numberline {1.1}Background}{5}{section.1.1}
\contentsline {section}{\numberline {1.2}Preliminary Data}{5}{section.1.2}
\contentsline {subsection}{\numberline {1.2.1}Comparison of Different Commercial Engines}{5}{subsection.1.2.1}
\contentsline {subsection}{\numberline {1.2.2}Grade Reading Level of Various Texts}{6}{subsection.1.2.2}
\contentsline {section}{\numberline {1.3}Automatic Speech Recognition Schematic for a Medical Setting}{6}{section.1.3}
\contentsline {subsection}{\numberline {1.3.1}AI-Complete and ASR-Complete}{6}{subsection.1.3.1}
\contentsline {section}{\numberline {1.4}Speech Enhancement}{6}{section.1.4}
\contentsline {subsection}{\numberline {1.4.1}Recurrent Neural Networks for Noise Suppression}{6}{subsection.1.4.1}
\contentsline {subsection}{\numberline {1.4.2}Non-Negative Matrix Factorization}{8}{subsection.1.4.2}
\contentsline {section}{\numberline {1.5}Blind Source Separation}{8}{section.1.5}
\contentsline {subsection}{\numberline {1.5.1}Independent Component Analysis}{8}{subsection.1.5.1}
\contentsline {subsection}{\numberline {1.5.2}Non-Negative Matrix Factorization (NMF) and Sparse NMF}{8}{subsection.1.5.2}
\contentsline {section}{\numberline {1.6}Speaker Diarisation}{9}{section.1.6}
\contentsline {section}{\numberline {1.7}Speaker Verification}{9}{section.1.7}
\contentsline {section}{\numberline {1.8}Speech Recognition}{9}{section.1.8}
\contentsline {subsection}{\numberline {1.8.1}Hidden-Markov Models and Gaussian Mixture Models}{9}{subsection.1.8.1}
\contentsline {subsection}{\numberline {1.8.2}Long Short Term Memory Networks}{9}{subsection.1.8.2}
\contentsline {section}{\numberline {1.9}Features from Speech}{9}{section.1.9}
\contentsline {chapter}{\numberline {2}Deep Learning Theory}{11}{chapter.2}
\contentsline {section}{\numberline {2.1}Deep Relaxation: PDEs for Optimizing Deep Neural Networks}{11}{section.2.1}
\contentsline {section}{\numberline {2.2}Characterization of Neural Networks as an Encoder-Decoder with Mutual Information}{11}{section.2.2}
\contentsline {section}{\numberline {2.3}The Stochastic Thermodynamics of Learning}{11}{section.2.3}
\contentsline {section}{\numberline {2.4}Residual Networks as a Mean-Field Optimal Control Problem}{11}{section.2.4}
\contentsline {chapter}{Appendices}{13}{section*.2}
\contentsline {chapter}{\numberline {A}Methodologies}{15}{Appendix.a.A}
\contentsline {section}{\numberline {A.1}Long Short-Term Memory and Gated Recurrent Unit}{15}{section.a.A.1}
\contentsline {section}{\numberline {A.2}Mel-Frequency Cepstrum Coefficients}{15}{section.a.A.2}
\contentsline {section}{\numberline {A.3}Linear Prediction Coefficients and its Derivatives}{15}{section.a.A.3}
\contentsline {chapter}{Bibliography}{17}{chapter*.3}
